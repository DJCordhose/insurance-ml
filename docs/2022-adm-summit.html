<!doctype html>
<html>

<head>
	<meta charset="utf-8">
	<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=10.0, user-scalable=yes">

	<title>AMD Summit 2022: ML</title>

	<link rel="stylesheet" href="revealjs/reveal.js/dist/reset.css" />
    <link rel="stylesheet" href="revealjs/reveal.js/dist/reveal.css" />
    <link rel="stylesheet" href="revealjs/reveal.js/dist/theme/white.css" />

    <!-- Theme used for syntax highlighted code -->
	<!-- <link rel="stylesheet" href="revealjs/reveal.js/plugin/highlight/monokai.css"> -->
	<link rel="stylesheet" href="revealjs/reveal.js/plugin/highlight/zenburn.css">
    <link rel="stylesheet" href="revealjs/highlight-js-github-theme.css" />
    <link rel="stylesheet" href="revealjs/styles.css" />

</head>

<body style="background-color: whitesmoke;">
	<div class="reveal">
		<div class="slides">

<!-- <section data-markdown class="local preparation hide">
</section> -->


<!-- 
Künstliche Intelligenz als Disziplin der Software Entwicklung

Klassische Business Logik eignet sich oft dafür, durch einen datengetriebenen Ansatz oder andere Techniken aus dem
Bereich der KI ersetzt zu werden. Man erhofft sich dadurch eine bessere Wartbarkeit, Robustheit und letztlich auch eine
bessere Genauigkeit.

In diesem Workshop werden wir ein Stück klassischen Code durch ein Maschine Learning Modell ersetzen. Dabei betrachten
wir die Frage, wo die Grenze eines solchen Modells sind, wie man es in eine ja meistens gegebene klassische Umgebung
einbindet und wie man entscheidet, ob ein großes Modell besser geeignet ist als mehrere kleine. Hier kommt die Frage
Monolith vs kleinere Services also von neuem wieder auf.

Technisch werden in einem Java Umfeld arbeiten und daher ist es vorteilhaft, eine Java Entwicklungsumgebung auf einem
Laptop mitzubringen. Letztlich ist aber jeder willkommen, da es eher um Prinzipien als Details im Code gehen wird.

---

Java Forum Nord: https://javaforumnord.de/site/2022/
https://jax.de/big-data-machine-learning/machine-learning-mit-java/

Machine Learning mit Java

Java ist die vorherrschende Sprache bei der Entwicklung von Geschäftsanwendungen, aber Machine Learning Anwendungen
werden meist mit Python entwickelt. Daraus resultiert die Frage: wie macht man als Java-Entwickler Machine Learning? Und
auch: wann ist das sinnvoll und wie ersetzt man evtl. bestehende Code mit einem solchen Modell und wie bindet man dieses
in die bestehende Anwendung ein?

In diesem Vortrag sehen wir uns anhand eines durchgängigen Code-Beispiels in Java an
- Warum sind verschachtelte ifs oft nicht genug?
- Welche Möglichkeiten gibt es, ein Stück Java-Code mit einem Machine Learning Modell zu ersetzen?
- Wie erzeugt man ein derartiges Modell und woran kann man ablesen, ob es gut ist?
- Was sind die besonderen Herausforderungen eines Machine Learning Modells in Produktion?

Als Framework für Machine Learning werden wir TensorFlow nutzen.

-->



<!-- 
<section data-markdown class="todo">
</section>
 -->
  <section data-markdown>
	<textarea data-template>
#### Bevor es los geht

### Künstliche Intelligenz als Disziplin der Software Entwicklung

<!-- https://api-summit.de/cloudnative-devops/kuenstliche-intelligenz-als-disziplin-der-software-entwicklung/ -->

Diese Folien: https://bit.ly/amd-summit-2022-ml (der einzige Link zum abtippen)

_Optional: Wenn du aktiv mitmachen möchtest_
1. Sicherstellen, dass du eine IDE und ein aktuelles JDK installiert hast (ab 11 sollte genügen)
1. Klonen: https://github.com/DJCordhose/insurance-ml
   1. `git clone https://github.com/DJCordhose/insurance-ml.git`
   1. https://github.com/DJCordhose/insurance-ml/archive/refs/heads/main.zip herunterladen wenn du kein Git hast
   1. forken und per ssh klonen wenn du dich gut mit Github auskennst
<!-- 1. Nachher gibt es noch Zeit, dies zu tun, also kein Stress -->

_Bei Problemen den Nachbar oder Olli fragen_   
</textarea>
</section>

  <section data-markdown>
				<textarea data-template>
# Künstliche Intelligenz als Disziplin der Software Entwicklung
                
API, Microservices und DDD Summit 2022, https://api-summit.de/cloudnative-devops/kuenstliche-intelligenz-als-disziplin-der-software-entwicklung/

Oliver Zeigermann
oliver.zeigermann@openknowledge.de

Folien: https://bit.ly/amd-summit-2022-ml

    </textarea>
			</section>

      <section data-markdown>
				<textarea data-template>
### Roter Faden			

_In diesem Workshop sehen wir uns anhand eines durchgängigen Code-Beispiels in Java an_
- Warum sind verschachtelte ifs oft nicht genug?
- Welche Möglichkeiten gibt es, ein Stück Java-Code mit einem Machine Learning Modell zu ersetzen?
- Wie erzeugt man ein derartiges Modell und woran kann man ablesen, ob es gut ist?
- Was sind die besonderen Herausforderungen eines Machine Learning Modells in Produktion?
</textarea>
</section>

<section data-markdown>
  <textarea data-template>
### Wer ist Olli

<div style="display: flex;">
<div style="flex: 50%;">
  <a href='https://oreilly.de/produkt/machine-learning-kurz-gut-2/'>
  <img src='img/ml-buch-v2.jpg' height="400">
  </a>
</div>
<div style="flex: 50%; font-size: x-large;">
  <img src='img/olli-opa.jpeg'>
</div>
</div>
<p>
<a target="_blank" href="mailto:oliver.zeigermann@openknowledge.de">Oliver Zeigermann</a>:
Head of AI@OpenKnowledge
</p>    
</textarea>
</section>

<section data-markdown>
	<textarea data-template>
### Wer seid ihr?

* Was macht ihr?
* Was wisst ihr schon?
* Warum seid ihr hier?
</textarea>
</section>

<section data-markdown>
	<textarea data-template>
# Agenda

1. Unsere Beispielanwendung
1. Klassische Regeln
1. Lösung mit Machine Learning (ML)
1. ML als Monolith?
1. Prodkutiver Betrieb
<!-- 1. Optionale Bonus Inspiration zum Abschluss: 5 ML Konzepte in 5 Minuten -->
</textarea>
</section>

<section data-markdown>
	<textarea data-template>
# Agenda

1. _Unsere Beispielanwendung_
1. Klassische Regeln
1. Lösung mit Machine Learning (ML)
1. ML als Monolith?
1. Prodkutiver Betrieb
</textarea>
</section>

<section data-markdown>
	<textarea data-template>
## Unser Beispiel: Vorhersage von Risiken

* Wir sind CTO einer hochinnovativen Kfz-Versicherungsgesellschaft
* Anders als andere Versicherungsgesellschaften bestimmen wir den Tarif anhand der geschätzen Anzahl von Unfällen pro Kunde
* Zielsetzung: Wie viele Unfälle werden die potenziellen Kunden haben?

<img src='img/pixabay/accident-151668_1280.png' style="height: 230px">
</textarea>
</section>

<section>
	<h3>Klassifizierung basierend auf bekannten Daten</h3>
	<img src="img/insurance-new/train-data.png" height="500px" class="fragment">
</section>


<section data-markdown>
	<textarea data-template>
### Vorhersage von Risiken für potenzielle Kunden

<a href='html/calculator.html'>
<img src='img/calculator.png' height="400">
</a>
<p><small>
<a href='html/calculator.html' target="_blank">
https://djcordhose.github.io/ml-resources/html/calculator.html</a></small>
</small></p>
</textarea>
</section>

<section data-markdown>
	<textarea data-template>
# Agenda

1. Unsere Beispielanwendung
1. _Klassische Regeln_
1. Lösung mit Machine Learning (ML)
1. ML als Monolith?
1. Prodkutiver Betrieb
</textarea>
</section>

<section data-markdown class="hands-on" style="font-size: x-large;">
	<textarea data-template>
### Hands-On 0: Installation und Orientierung im Projekt

_Installation_
1. Sicherstellen, dass du eine IDE und ein aktuelles JDK installiert hast (ab 11 sollte genügen)
1. Klonen: https://github.com/DJCordhose/insurance-ml
   1. `git clone https://github.com/DJCordhose/insurance-ml.git`
   1. https://github.com/DJCordhose/insurance-ml/archive/refs/heads/main.zip herunterladen wenn du kein Git hast
   1. forken und per ssh klonen wenn du dich gut mit Github auskennst

_Das Beispiel_
1. Im Verzeichnis `workspace-java` ist ein Java-Projekt vorbereitet
1. In `workspace-java/app/src/main/java/eu/zeigermann/ml/App.java` gibt es ein Code-Gerüst für diesen Workshop
1. `./gradlew run --args="../../data/insurance-customers-risk-1500.csv"` (`gradle.bat` auf Windows) starten das Projekt und gibt den Anteil richtiger Vorhersagen aus
1. `App.predictFromRules` wandelt eine Liste von Datensätzen in Predictions um

	</textarea>
</section>

<section data-markdown class="hands-on">
	<textarea data-template>
### Hands-On I: Klassische Regeln formulieren		

1. Tut euch in Teams von mindestens 2 Personen zusammen
1. Mindestens eine Person sollte Java-Code auf dem eigenen Rechner ausführen können
1. Diskutiert wie ihr die Aufgabe mit klassischen Regeln lösen könnt
1. Implementiert die Regeln in `App.predictFromRules` und bestimmt wie gut diese das Problem lösen
1. Wie weit könnt ihr den Score von 33% nach oben bringen?

Optional
1. Ändert die einzulesende Datei auf `insurance-customers-risk-1500-test.csv`
1. Wie verändert sich der Score?
1. Wie interpretierst du die Veränderung des Scores?
	</textarea>
</section>

<section data-markdown>
	<textarea data-template>
### Reflektion

## Ist das eigentlich eine gute Lösung?

### Was könnten die Schwierigkeiten sein?

</textarea>
</section>

<section data-markdown class="fragments">
	<textarea data-template>
### Mögliche Schwierigkeiten

* Zumindest haben wir eine Metrik
  * Aber ist das eigentlich die beste Lösung?
* Bewertet ihr sonst eure Geschäftslogik?
  * Welche Art von Geschäftslogiken kennt ihr?  
* Wirkt das Vorgehen sturktuiert?
* Was machen wir wenn die Welt sich ändert?
* Woher wissen wir, *dass* die Welt sich relevant ändert?
* Könnt ihr euch Probleme vorstellen, die gar nicht mit (von Menschen geschriebenen) Regeln zu lösen sind?
  * Bilder
  * Textverständnis
  * Hochdimensionale Probleme

</textarea>
</section>


<section data-markdown>
	<textarea data-template>
# Agenda

1. Unsere Beispielanwendung
1. Klassische Regeln
1. _Lösung mit Machine Learning (ML)_
1. ML als Monolith?
1. Prodkutiver Betrieb
</textarea>
</section>

<section data-markdown>
	<textarea data-template>
### Was ist Machine Learning?    

_Ein Ansatz zur Entwicklung von Software, bei dem die Software nicht von Hand geschrieben wird, 
sondern die Maschine auf der Grundlage der gegebenen Beispiele und der gegebenen Rahmenbedingungen herausfindet, 
was zu tun ist_

</textarea>
</section>

<section data-markdown>
  <textarea data-template>
### Artificial Intelligence (AI) vs Machine Learning (ML)

<img src='img/AI.png'>

</textarea>
</section>

<section data-markdown>
	<textarea data-template>
### Ist diese KI Teufelszeug?

<img src='img/sw2-clem.png' style="height: 250px">

<small>
    
https://twitter.com/ClementDelangue/status/1536514359450652674

</small>

	</textarea>
</section>

<section data-markdown>
	<textarea data-template>
<img src='img/classic-development.jpg' style="height: 600px;">
</textarea>
</section>

<section data-markdown>
	<textarea data-template>
<img src='img/supervised-ml.jpg' style="height: 600px;">
</textarea>
</section>

<section data-markdown>
	<textarea data-template>
### Man muss sein Problem so formulieren, dass es für ML greifbar wird

<img src='img/software-complexity.png'>

<small>
Andrej Karpathy - TRAIN AI 2018 - Building the Software 2.0 Stack

https://vimeo.com/272696002

</small>
	</textarea>
</section>


<section data-markdown>
	<textarea data-template>
### Wann macht ML Sinn?

_Die Lösung des vorliegenden Problems ist unbekannt oder schwer zu spezifizieren_

_Und_

* Es gibt eine klare, einfache Eingabe und bestenfalls auch Ausgabe 
* Es gibt Muster in der Eingabe, die zur Vorhersage verwendet werden können
* Die Lösung des Problems kann Fehler oder Unsicherheiten tolerieren
* Wir sind bereit und in der Lage, in einer initialen Phase Experimente mit offenem Ausgang durchzuführen
</textarea>
</section>


<section data-markdown>
    <textarea data-template>
### Machine Learning können in Phasen strukturiert werden

<img src='img/sketch/phases-ml.png'>

</textarea>
</section>

	<section data-markdown class="fragments">
### Phase 1: Exploration

* in der ersten Phase eines Machine Learning Projekts wird die Anwendungsidee validiert und ein
funktionsfähiges Modell entwickelt.
* dabei ist ein schnelles iterieren und ausprobieren von Ideen zentral
* das Ziel ist *nicht* ein sinnvolles Stück Software
* Scripting passt hier besser als Programmieren als Ausdruck für die Tätigkeit
* das Ziel ist eine schnelle Entwicklung
* Phase 1 endet entweder mit
  * einem funktionsfähigen Modell mit dem man in Phase II übergeht oder
  * dem Verwerfen des Ansatzes

	</section>

<section data-markdown>
  <textarea data-template>
## Und wie machen wir das nun?    
  </textarea>
</section>

<section data-markdown>
### Neuronale Netzwerke sind ein mächtiges Mittel für ML	
## TensorFlow is defacto Standard

_TensorFlow is an end-to-end open source platform for machine learning. It has a comprehensive, flexible ecosystem of
tools, libraries and community resources that lets researchers push the state-of-the-art in ML and developers easily
build and deploy ML powered applications._

https://www.tensorflow.org/
</section>

<section data-markdown>
## Aber mit welcher Programmiersprache?

### Und wieso ist das eigentlich Python? (Spoiler)
</section>

<section data-markdown>
	<textarea data-template>
### Unterschiedliche Projekte für TensorFlow mit Java

1. https://github.com/tensorflow/tensorflow/blob/master/tensorflow/java/README.md
   * Alte Version auf Basis von JNI, nur Core für die Ausführung von Modellen
   * https://www.tensorflow.org/api_docs/java/org/tensorflow/package-summary
   * Stabil, aber veraltet
1. https://www.tensorflow.org/jvm
  * Das aktuelle Projekt
  * Unterstützt nicht nur Deployment, sondern die volle API inkl. Training
  * Hat strategische Bedeutung, ist aber noch nicht stabil
  * Unterprojekt: https://github.com/tensorflow/java-ndarray

</textarea>
</section>

<section data-markdown>
	<textarea data-template>
### TensorFlow Java hat seine eigene Version

Stabilitätsgarantien gelten nicht für Java

<img src="img/tf-java-versions.png">

https://github.com/tensorflow/java/#tensorflow-version-support
</textarea>
</section>

<section data-markdown class="fragments">
	<textarea data-template>
### Aber: Wieso eigentlich Neuronale Netzwerke in Java?        

* Training von Neuronalen Netzen ist eher Scripting
* Sprachmittel von Java sind nach wie vor umständlich für Scripting
* Aber: vielleicht reicht eine einfache Integration eines ML-Modells in Java mit Standard-Schnittstellen?
  * GRPC, REST, MQTT, etc.  

    </textarea>
</section>

	<section data-markdown>
		<textarea data-template>
### Analogie: Build-Tool und ML-Training

* Ein Build-Script macht aus Java-Quellen ein ausführbares Programm
* Ein Trainings-Script macht aus einer ML-Architektur und Daten ein ausführbares TensorFlow Modell
* Ein Build-Script schreiben wir auch in Java nicht in Java selbst
* Entweder nutzen wir eine Script-Sprache (Groovy oder Kotlin)
* Oder eine noch weiter standadisierte, deklarative Beschreibung (XML)
</textarea>
</section>

<section data-markdown>
	<textarea data-template>
### Python für ML

* Python ist perfekt für Scripting
* Hat die größte Community in dem Bereich
* Python hat die besten Bibliotheken und Werkzeuge
</textarea>
</section>


	<section data-markdown>
<textarea data-template>
## ML Training als (Build) Script	
### Literate Statistical Programming

1. Intent
1. Code
1. Data
1. Results
1. (Interpretation)

_Die Idee wird in sogenannten "notebooks" implementiert_

<small>https://en.wikipedia.org/wiki/Literate_programming</small>
<br>
<small>https://education.arcus.chop.edu/literate-statistical-programming/</small>

</textarea>
</section>

<section data-markdown style="font-size: x-large;">
	<textarea data-template>
## Live Coding - Notebooks, interaktive Skripte

### Wie fühlt sich Arbeit in Notebooks an?

https://colab.research.google.com/github/DJCordhose/insurance-ml/blob/main/workspace-java/insurance_ml.ipynb

</textarea>
</section>

<section data-markdown class="hands-on">
	<textarea data-template>
### Hands-On II		

1. Bringe das Notebook auf Colab zum laufen
1. Trainiere ein eigenes Modell und lade es auf deinen Rechner herunter
</textarea>
</section>


<section data-markdown>
	<textarea data-template>
# Agenda

1. Unsere Beispielanwendung
1. Klassische Regeln
1. Lösung mit Machine Learning (ML)
1. _ML als Monolith?_
1. Prodkutiver Betrieb
</textarea>
</section>

<section data-markdown>
    <textarea data-template>
<img src='img/mlops/mlops-systems.png'>					

<small>

https://twitter.com/nkoumchatzky/status/1525904101619417095
</small>

    </textarea>
</section>

<section data-markdown>
  <textarea data-template>
### Spezielle Anforderungen an die Entwicklung von ML Anwendungen

* Modelle so zähmen / trainieren, dass sie überhaupt funktionieren
* Debuggen
* In-/Output kodieren
* Fallback für invalide Input- oder Output-Bereiche
* Automatisierte Tests

</textarea>
</section>

<section data-markdown>
	<textarea data-template>
### Ein großes Modell oder (mehrere) kleinere

<img src="img/mlops/Micro-ML.png">
</textarea>
</section>

<!-- <section data-markdown>
	<textarea data-template>
### Ein großes Modell oder (mehrere) kleinere		
<img src="img/sketch/small-model.jpg">
</textarea>
</section> -->

<section data-markdown>
	<textarea data-template>
# Agenda

1. Unsere Beispielanwendung
1. Klassische Regeln
1. Lösung mit Machine Learning (ML)
1. ML als Monolith?
1. _Prodkutiver Betrieb_
</textarea>
</section>

<section data-markdown>
	<textarea data-template>
### Wie bringt man denn ein Modell in Produktion???

|   | Quelle | Vorgehen | Artefakt für die Produktion |
|---|---|---|---|
| *Traditionelle Entwicklung* | Modell | Regeln | Programm |
| *Maschinelles Lernen* | Daten und Priors | ML-Algorithmus | *Modell* |
|   |   |   |

</textarea>
</section>


<section data-markdown>
  <textarea data-template>
## Deployment ist ein Schwerpunkt von TensorFlow

<img src='img/tf-deploy.png'>

<small>

* https://www.tensorflow.org/tfx/guide/serving
* https://www.tensorflow.org/lite/api_docs
* https://www.tensorflow.org/js

</small>

</textarea>
</section>


<section data-markdown>
	<textarea data-template>
### TensorFlow Modelle können als Graph abgespeichert werden

<img src="https://raw.githubusercontent.com/tensorflow/docs/master/site/en/guide/images/intro_to_graphs/two-layer-network.png">

* https://www.tensorflow.org/guide/intro_to_graphs
* https://www.tensorflow.org/api_docs/python/tf/Graph#as_graph_def 
</textarea>
</section>

<section data-markdown class="fragments">
	<textarea data-template>
### Warum interessiert uns das?

* Graphen enthalten alles was man zur Ausführung eines Neuronalen Netzes braucht
* Damit kann man die Python-Welt verlassen
* Man braucht lediglich eine Umgebung, die die Operationen in dem Graphen ausführen kann
* So eine Umgebung ist bereits in TensorFlow mit C++ implementiert und auch die Python-Version beruht darauf  
</textarea>
</section>

<section data-markdown>
	<textarea data-template>
### Serving

* Erlauben direkt Ausführung eines Graphen im Server-Betrieb
* Modell-Server kann lokal unter Linux installiert werden
* Oder man kann so ein Modell direkt bei GCP deployen
</textarea>
</section>

<section data-markdown>
	<textarea data-template>
### Serving

```
saved_model_cli show --dir insurance-classifier --all
```

```
export TF_CPP_VMODULE=http_server=1

nohup tensorflow_model_server --port=8500 --rest_api_port=8501 \
  --model_name=insurance --model_base_path=/home/olli/insurance-model  >server.log 2>&1
```

https://www.tensorflow.org/tfx/guide/serving
https://www.tensorflow.org/tfx/serving/setup
</textarea>
</section>

<section>
<h3>TensorFlow Modelle können auch direkt aus Java aufgerufen</h3>

<pre>
    <code data-trim><script type="text/template">
try (var savedModelBundle = SavedModelBundle.load("insurance-ml/app/classifier", "serve")) {

    var input_matrix = NdArrays.ofFloats(Shape.of(1, 2));
    input_matrix.set(NdArrays.vectorOf(48.0f, 100.0f), 0);
    Tensor input_tensor = TFloat32.tensorOf(input_matrix);
    Map<String, Tensor> inputTensorMap = new HashMap<>();
    inputTensorMap.put("input", input_tensor);

    var myFunction = savedModelBundle.function("serving_default");
    Map<String, Tensor> outputTensorMap = myFunction.call(inputTensorMap);
    var prediction = outputTensorMap.get("output");

    // overly complicated way to get the prediction, but so far found no better way
    var probas = prediction.asRawTensor().data().asFloats();
    float redProba = probas.getFloat(0);
    float yellowProba = probas.getFloat(1);
    float greenProba = probas.getFloat(2);
}
        
</script></code>
</pre>
</section>

<section data-markdown>
	<textarea data-template>
### Lokale Vorhersage

```
gcloud ai-platform local predict --model-dir /home/olli/insurance-model/1 \
  --json-instances  sample_insurance.json \
  --framework tensorflow
```

https://cloud.google.com/ai-platform/prediction/docs/deploying-models#test_your_model_with_local_predictions
</textarea>
</section>


<!-- 

ACHTUNG: DAS HIER IST AKTUELLER ALS DIE NÄCHSTEN BEIDEN FOLIEN

gcloud auth login
gcloud config set project ml-project-213311

// https://cloud.google.com/storage/docs/naming-buckets?_ga=2.159882297.-561421399.1653816440
gsutil mb gs://eu_zeigermann_ml_insurance_1
gsutil cp -R /home/olli/insurance-model/1 gs://eu_zeigermann_ml_insurance_1


gcloud ai-platform models create "ml_insurance" --region=europe-west1 --enable-logging
gcloud ai-platform versions create "v1" --model "ml_insurance" --region=europe-west1 --framework tensorflow  --runtime-version=2.8 --origin "gs://eu_zeigermann_ml_insurance_1/1"
gcloud ai-platform versions describe "v1" --region=europe-west1 --model "ml_insurance"

gcloud ai-platform predict --region=europe-west1 --model "ml_insurance" --version "v1" --json-instances sample_insurance.json

Aufruf aus Java: https://cloud.google.com/ai-platform/prediction/docs/online-predict#java
Dependencies: https://github.com/GoogleCloudPlatform/java-docs-samples/blob/ab20245137332ff8ba6285f9a66f3f8bb1558b52/mlengine/online-prediction/pom.xml
 -->
        <section>
<h3>Modell auf Google Clound ML deployen</h3>

<div class="fragment">
    <p>Modell in einen Cloud Bucket kopieren</p>
<pre><code contenteditable data-trim class="python">
gsutil mb gs://eu_zeigermann_ml_insurance_1
gsutil cp -R /home/olli/insurance-model/1 gs://eu_zeigermann_ml_insurance_1
</code></pre>
<p><small>
Erfordert Google Cloud SDK:         
    <a href='https://cloud.google.com/sdk/install'>https://cloud.google.com/sdk/install</a></small></p>
</div>
<div class="fragment">
    <p>Deployment aus diesem Bucket</p>
<pre><code contenteditable data-trim class="python">
gcloud ai-platform models create "ml_insurance" --region=europe-west1 --enable-logging
gcloud ai-platform versions create "v1" --model "ml_insurance" --region=europe-west1 --framework tensorflow \
 --runtime-version=2.8 --origin "gs://eu_zeigermann_ml_insurance_1/1"
gcloud ai-platform versions describe "v1" --region=europe-west1 --model "ml_insurance"
</code></pre>
<p><small>
<a href='https://cloud.google.com/ml-engine/docs/tensorflow/deploying-models'>
    https://cloud.google.com/ml-engine/docs/tensorflow/deploying-models</a>
<br>
<a href='https://cloud.google.com/ml-engine/docs/tensorflow/prediction-overview#prediction_logging'>
    https://cloud.google.com/ml-engine/docs/tensorflow/prediction-overview#prediction_logging</a></small></p>
</div>

    </section>

<section>
<h3>Anfragen</h3>

<div class="fragment">
    <p>Das Input-format ist ein bisschen sonderbar</p>
<pre><code contenteditable data-trim class="python">
# sample_insurance.json    
{"input": [ 18, 160 ]}
{"input": [ 51, 100]}
{"input": [ 20, 90]}    
</code></pre>
</div>
<div class="fragment">
    <p>Aufruf</p>
<pre><code contenteditable data-trim class="python fragment">
gcloud ai-platform predict --region=europe-west1 --model "ml_insurance" --version "v1" \
 --json-instances ./sample_insurance.json

</code></pre>
<pre><code contenteditable data-trim class="python fragment">
Wahrscheinlichkeiten pro Klasse
[[0.982429862, 0.0175378807, 3.22602682e-05], 
[0.012407572, 0.333301514, 0.654291], 
[0.00413073646, 0.985944033, 0.00992520899]]
</code></pre>
</div>

<p><small>
<a href='https://cloud.google.com/ml-engine/docs/tensorflow/online-predict'>https://cloud.google.com/ml-engine/docs/tensorflow/online-predict</a>
</small></p>

</section>

        <!-- <section class="todo">
<h3>Making Predictions from Python</h3>

<div class="fragment">
    <p>First we need a few more libraries</p>
<pre><code contenteditable data-trim class="python">
pip install google-api-python-client
pip install tensorflow-serving-api
</code></pre>
</div>
<div class="fragment">
    <p>Input needs to conform to JSON now</p>
<pre><code contenteditable data-trim class="python">
instances = [{"inputs": [100,  47,  10]}]
predict_json("ml_project", "ml_insurance", instances=instances)
</code></pre>
<pre><code contenteditable data-trim class="python fragment">
[{'scores': 
  [0.002760800765827298, 0.8720880746841431, 0.12515118718147278]}]
</code></pre>
</div>

<p><small>
<a href='https://cloud.google.com/ml-engine/docs/tensorflow/online-predict'>https://cloud.google.com/ml-engine/docs/tensorflow/online-predict</a>
</small></p>

    </section>

            <section class="todo">
<h3>Python API</h3>

<div class="fragment">
<pre><code contenteditable data-trim class="python">
import googleapiclient.discovery

def predict_json(project, model, instances):
    service = googleapiclient.discovery.build('ml', 'v1')
</code></pre>
<pre><code contenteditable class="python fragment">    name = 'projects/{}/models/{}'.format(project, model)

    response = service.projects().predict(
        name=name,
        body={'instances': instances}
    ).execute()

    return response['predictions']</code></pre>
</div>

<p><small>
<a href='https://cloud.google.com/ml-engine/docs/tensorflow/online-predict'>https://cloud.google.com/ml-engine/docs/tensorflow/online-predict</a>
<br>
<a href='https://github.com/GoogleCloudPlatform/python-docs-samples/blob/master/ml_engine/online_prediction/predict.py'>
    https://github.com/GoogleCloudPlatform/python-docs-samples/blob/master/ml_engine/online_prediction/predict.py
</a>

</small></p>

    </section>

        <section class="todo">
<h3>TensorFlow Serving REST API</h3>

<div class="fragment">
<p>Starting the Model Server in Rest Mode (needs Linux)</p>

<pre><code contenteditable data-trim>
tensorflow_model_server --rest_api_port=8501 \
--model_name=manning_insurance_1 \
--model_base_path=$(pwd)/tf
</code></pre>
<p><small><a href='https://www.tensorflow.org/serving/api_rest'>https://www.tensorflow.org/serving/api_rest</a></small></p>
</div>

<div class="fragment">
<p>Curling to it</p>

<pre><code contenteditable data-trim class="python">
curl -X POST \
http://localhost:8501/v1/models/manning_insurance_1:predict  \
-d '{ "instances": [{"inputs": [ 100.0,  47.0,  10.0]}]}' 
# {
#     "predictions": [[0.0027608, 0.872088, 0.125151]]
# }</code></pre>
</div>

<p class="fragment"><small>
    <em>Note</em>: To make this work from a browser you need a server in between, because 
    <a href='https://enable-cors.org/'>CORS</a> makes an 
    <a href='js/serving-sandbox.html'>
        OPTION request</a>
     that is not implemented by model server</small></p>

    </section>
 -->

<section data-markdown>
### Alternative: ML auf Edge Devices deployen

* _Datenschutz_: Eingabedaten für das Modell verlassen das Gerät nicht
* _Latenz_: Vorhersage wird lokal ausgeführt
* _Zugang zu Echtzeit-Sensordaten_: Modell kann zur Entwicklung interaktiver Erlebnisse verwendet werden, die lokale Sensordaten nutzen, z. B. Beschleunigungsmesser, Gyroskop, Mikrofon usw.
* _Kosten_: es müssen keine Server für die Vorhersagen betrieben werden

</section>

<section data-markdown>
### Auf Mobile deployen

* https://www.tensorflow.org/lite
* https://www.tensorflow.org/lite/guide/ios
* https://www.tensorflow.org/lite/android
* http://newsletter.victordibia.com/issues/running-machine-learning-models-on-android-devices-issue-9-1199608
* https://developers.google.com/learn/topics/on-device-ml
</section>
    
        <section>
<h3>Im Browser deployen</h3>

<div class="fragment">
<p>Keras Model nach TensorFlow.js konvertieren</p>

<pre><code contenteditable data-trim class="python">
tensorflowjs_converter --input_format keras \
./model/insurance.hdf5 \
./tfjs    
</code></pre>
<p><small><a href='https://js.tensorflow.org/tutorials/import-keras.html'>
    https://js.tensorflow.org/tutorials/import-keras.html</a></small></p>

</div>


<div class="fragment">
<p>Nutzung im Browser</p>

            <pre><code contenteditable data-trim class="fragment line-numbers javascript">
const model = await tf.loadModel('tfjs/model.json');
            </code></pre>
            <pre><code contenteditable data-trim class="fragment line-numbers javascript">
// age, max speed
const example = tf.tensor([[47, 100]]);
const prediction = model.predict(example);
console.log(await prediction.data());
//[0.00334801129065454, 0.8710343241691589, 0.12561771273612976]
    </code></pre>
<p><small><a href='html/calculator.html'>
    https://djcordhose.github.io/insurance-ml/html/calculator.html</a></small></p>
    
    </div>   
    </section>

<section data-markdown>
### TensorFlow auf AWS    

* Mit Sagemaker entwickeln
  * https://aws.amazon.com/de/tensorflow/
  * https://aws.amazon.com/de/getting-started/hands-on/train-tune-deep-learning-model-amazon-sagemaker/
* Nur serven 
  * einfach über das normale `tensorflow_model_server`
  * Es gibt dafür ein fertiges Deep Learning AMI: https://docs.aws.amazon.com/dlami/
  * https://docs.aws.amazon.com/dlami/latest/devguide/tutorial-tfserving.html  
</section>

<section data-markdown class="hands-on">
	<textarea data-template>
### Hands-On III		

1. Binde das Modell in deinen Java-Code ein
1. Entweder als direkten Aufruf
1. Oder wandle das Modell in JS, um es direkt im Browser zu nutzen
   * https://www.tensorflow.org/js/tutorials/conversion/import_saved_model 
1. Oder rufe einen Server auf
   1. starte einen TensorFlow Server (geht nur unter Linux)
      * https://www.tensorflow.org/tfx/serving/setup
   1. oder bringe da Modell in der Cloud zum laufen
      * https://cloud.google.com/ai-platform/prediction/docs/deploying-models
1. Wie ist der Score des Modells mit den beiden Datensätzen? 

_Wähle den direkten Aufruf, es sei denn du hast bereits Erfahrung in den anderen Varianten der Produktion_
</textarea>
</section>

<section data-markdown class="fragments">
	<textarea data-template>
### Wir lassen das System ein bisschen in Produktion laufen

Mal sehen wie sich das System macht

- Information über Schadensfälle neuer Kunden kommen nur verzögert
- Aber neue Meldungen über Schandensmeldungen kommen permanent
- Wir haben keine explizite Kontrolle darüber, wer bei uns versichert werden will und wessen Unfalldaten wir bekommen
- Es gibt aber eine Tendenz dahin, dasss eher Kunden mit guten Konditionen kommen

<!-- <small>

https://colab.research.google.com/github/DJCordhose/ml-resources/blob/main/notebooks/mlops/3_mlops_shift.ipynb
</small> -->

</textarea>
</section>

<section data-markdown>
	<textarea data-template>

<!-- <img src='img/6monts-later.jpg' height="600px"> -->
<img src='img/2year-later.jpg' height="600px">

</textarea>
</section>


<section data-markdown data-transition="none">
	<textarea data-template>
## Ergebnis des Modells nach zwei Jahren

<img src='img/insurance-new/insurance-after-shift.png' class="fragment">

</textarea>
</section>


<section data-markdown data-transition="none">
	<textarea data-template>
## Ursprüngliche Daten zum direkten Vergleich

<img src='img/insurance-new/insurance-pred.png'>

</textarea>
</section>

<section data-markdown class="fragments">
	<textarea data-template>
### Was ist hier passiert? 

*Die Welt steht nicht still - Model und Welt laufen auseinander, aus 70% Genauigkeit werden 65%*

* Elektroautos finden weitere Verbreitung
* potente Elektroautos haben allgemein deutlich geringere Höchstgeschwindigkeit 
* aber super Beschleunigung
* Gute Beschleunigung ist viel eher Ursache für rasante Fahrweise, Unfallwahrscheinlichkeit ist hoch
* Wir haben aber nur Höchstgeschwindigkeit als Daten (seht im Fahrzeugschein), Korrelation war angenommen
* Der Cluster mit jungen, schlechten Fahrern ist nach unten gerutscht
* _Wird nun fälschlich als gut vorhergesagt und werden günstig versichert_
<!-- * Tatsächlich sehen wir aber viele Unfälle -->
<!-- - Faherer vielleicht ein bisschen älter geworden -->
</textarea>
</section>

<!-- <section data-markdown>
	<textarea data-template>
<img src='img/model-eval.png'>

<small>

https://twitter.com/marktenenholtz/status/1528021809697792003</small>
		</textarea>
</section>
	 -->
<section data-markdown class="fragments">
### Grundregel

* Alle haben Probleme in Produktion
* Es gibt kein fehlerfreies System 
  * jedenfalls nicht für lange
* Ziel ist es, Fehler schnell 
  * zu entdecken
  * zu analysieren
  * und entsprechende ihrer Schwere zu adressieren

</section>

<section data-markdown class="fragments">
  <textarea data-template>
## MLOps

_Standardisierung und Rationalisierung des Lebenszyklusmanagements von Machine Learning Projekten_

- **Es gibt viele Abhängigkeiten**
  * Daten und geschäftlichen Anforderungen ändern sich
  * Ergebnisse müssen in das Unternehmen zurückgespielt werden
- **Nicht jeder spricht dieselbe Sprache**
  * Fachabteilung, Data Scientists und IT müssen zusammenspielen
  * Tools, Sprache und mentale Modelle sind unterschiedlich
- **Data Scientists sind keine Software-Entwickler und anders herum**
  * beide Rollen haben unterschiedliche Ausbildungen und unterschiedliche Herangehensweisen
  * eine einzelne Person kann kaum beide Rollen abdecken 

</textarea>
</section>

<section data-markdown>
  <textarea data-template>
### Der Ablauf

<img src='img/mlops/mlops.png'>
</textarea>
</section>

<section data-markdown>
  <textarea data-template>
### Anforderungen an ML-Projekte

<img src='img/mlops/mlops-requirements.png'>

GoogleIO 2021 - Does your app use ML? Make it a product with TFX | Session
https://www.youtube.com/watch?v=NHIfUGpHZZw
</textarea>
</section>

	<section data-markdown class="fragments">
		<textarea data-template>
### Woher weiß man, dass man ein neues Modell in Produktion braucht?

1. Mindestens einmal im Jahr, damit man überhaupt noch weiß wie es geht
1. Wenn die Metrik des Modells nachlässt in Produktion
1. Dafür braucht man die Ground Truth der Daten aus Produktion
1. Manchmal bekommt man diese unmittelbar nach der Vorhersage durch die Reaktion eines menschlichen Benutzers
1. Oft aber auch erst nach nennenswerter Verzögerung 
1. Wenn sich die Verteilung der Daten der Anfragen deutlich von denen des Trainings unterscheiden 

</textarea>
	</section>

<section data-markdown class="hands-on">
	<textarea data-template>
### Hands-On IIIb		

1. Der Datensatz `insurance-customers-risk-1500-shift.csv` drückt den beschriebenen Shift aus
1. Bestimme die Performance des Modelle mit diesem Datensatz
1. Wie würdest du mit den unterschiedlichen Ansätzen auch diesen Datensatz gut abdecken?
<!-- 1. Wie würde das mit mehr als 2 Dimensionen funktionieren? -->
</textarea>
</section>

<section data-markdown class="fragments">
	<textarea data-template>
# Zusammenfassung

* ML kann eine Alternative zu Regeln sein wenn diese dynamisch sind
* Anhand von Daten kann man ein Neuronales Netz trainieren
* Dabei ist die Allgemeinheit des Modells am wichtigsten
* Ein ML-Modell steht nicht für sich, es ist immer ein Teil eines größeren Systems
* Eine Geschäftslogik (egal ob klassisch oder ML basiert) muss sich mit der Welt mitentwickeln
  * In klassischen Systemen bekommt man oft nicht mit, dass die Geschäftslogik veraltet
</textarea>
</section>

<!-- <section data-markdown class="local">
  <textarea data-template>
## Bonus Inspiration zum Abschluss

* Heute ist mein letzter Workshop einer langen Reihe von Talks und Konferezen (über Montate) vor der Sommerpause
* Wer gehen möchte kann nun beruhigt gehen
* Wer sich noch Konzepte über ML ansehen möchte wird danach von mir direkt auf ein Bier eingeladen
* Bei erfolgter Inspiration gern weitere Gespräche bei diesen Bieren 

https://bit.ly/ai-2022
</textarea>
</section> -->

			<section data-markdown>
				<textarea data-template>
# Vielen Dank

Künstliche Intelligenz als Disziplin der Software Entwicklung

API, Microservices und DDD Summit 2022, https://api-summit.de/muenchen/

Bleibt gern im Kontakt

Oliver Zeigermann

https://www.linkedin.com/in/oliver-zeigermann-34989773/

oliver.zeigermann@openknowledge.de

https://twitter.com/DJCordhose

Folien: https://bit.ly/amd-summit-2022-ml

    </textarea>
			</section>


		</div>
	</div>

	<script src="revealjs/reveal.js/dist/reveal.js"></script>
	<script src="revealjs/reveal.js/plugin/notes/notes.js"></script>
	<script src="revealjs/reveal.js/plugin/markdown/markdown.js"></script>
	<script src="revealjs/reveal.js/plugin/highlight/highlight.js"></script>
	<script src="revealjs/config.js"></script>


</body>

</html>